{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilFDlnRtPkmy"
   },
   "outputs": [],
   "source": [
    "# Dont Delete\n",
    "# model_cnn7 = models.Sequential([\n",
    "#         layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "#         # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "#         layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'), # Try (5,3)--------------------\n",
    "#         # layers.MaxPooling2D((2,2)),\n",
    "      \n",
    "#         layers.Conv2D(filters=64,kernel_size=(2,2),activation='relu'),   \n",
    "\n",
    "#         layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu'), # Try (4,3)------------------------\n",
    "#         # layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "#         layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu'), # Try (4,3)------------------------\n",
    "#         # layers.MaxPooling2D((2,2)),\n",
    "             \n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "#         layers.Dense(4, activation='softmax')\n",
    "#     ])\n",
    "# model_cnn7.compile(loss = 'categorical_crossentropy',\n",
    "#                   optimizer = Adam(learning_rate = 0.0002, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "#                   metrics = ['accuracy'])\n",
    "# MODEL_7=model_cnn7.fit(X_train,y_train, epochs=12, verbose=1)\n",
    "\n",
    "# filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), \n",
    "# groups=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "# kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
    "# bias_constraint=None, *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lUUrfBrPH0r3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pandas_profiling import ProfileReport\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFAZkd8SIikI"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bJu6mYv6H0r_"
   },
   "outputs": [],
   "source": [
    "cols = np.arange(8192)\n",
    "cols = cols.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DLASSIGN1\\train\\tr_images.csv', names = cols)\n",
    "tr_lbl = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DLASSIGN1\\train\\tr_labels.csv', names =['C1','C2','C3','C4'])\n",
    "ts_img = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DLASSIGN1\\valid\\vl_images.csv',names = cols)\n",
    "ts_lbl = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DLASSIGN1\\valid\\vl_labels.csv',names =['C1','C2','C3','C4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "m4_GeNdGH0sA"
   },
   "outputs": [],
   "source": [
    "# tr_img = pd.read_csv('/content/drive/MyDrive/train/tr_images.csv', names = cols)\n",
    "# tr_lbl = pd.read_csv('/content/drive/MyDrive/train/tr_labels.csv', names =['C1','C2','C3','C4'])\n",
    "# ts_img = pd.read_csv('/content/drive/MyDrive/valid/vl_images.csv',names = cols)\n",
    "# ts_lbl = pd.read_csv('/content/drive/MyDrive/valid/vl_labels.csv',names =['C1','C2','C3','C4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "d2NWrjZAH0sC"
   },
   "outputs": [],
   "source": [
    "tr_all = pd.concat([tr_img, tr_lbl], axis = 1)\n",
    "ts_all = pd.concat([ts_img, ts_lbl], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yOQilA1fH0sG"
   },
   "outputs": [],
   "source": [
    "tr_all['class'] = 0\n",
    "ts_all['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uR3IS5GsH0sI"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tr_all['class'][tr_all.C1 == 1.0] = 0\n",
    "tr_all['class'][tr_all.C2 == 1.0] = 1\n",
    "tr_all['class'][tr_all.C3 == 1.0] = 2\n",
    "tr_all['class'][tr_all.C4 == 1.0] = 3\n",
    "\n",
    "ts_all['class'][ts_all.C1 == 1.0] = 0\n",
    "ts_all['class'][ts_all.C2 == 1.0] = 1\n",
    "ts_all['class'][ts_all.C3 == 1.0] = 2\n",
    "ts_all['class'][ts_all.C4 == 1.0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qXvZLafvH0sL"
   },
   "outputs": [],
   "source": [
    "tr_n1 = tr_all.drop(['C1','C2','C3','C4'],axis = 1)\n",
    "ts_n1 = ts_all.drop(['C1','C2','C3','C4'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tk6woPjvH0sN"
   },
   "outputs": [],
   "source": [
    "col = ['class']\n",
    "X_Train = tr_n1.drop(columns = col, axis = 1)\n",
    "X_Test = ts_n1.drop(columns = col, axis = 1)\n",
    "y_Train=tr_n1['class']\n",
    "y_Test=ts_n1['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uGrjfeAhNgDk"
   },
   "outputs": [],
   "source": [
    "x_train = np.array(X_Train).reshape(3200,64, 128)\n",
    "x_test = np.array(X_Test).reshape(800,64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nf0f5TL1H0sP"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(tr_lbl)\n",
    "y_test = np.array(ts_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RHXBPXu7H0sS"
   },
   "outputs": [],
   "source": [
    "# Perform visualizations. \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57eNGxNMH0sT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(1100,1105,1):\n",
    "#     image = x_train[i]\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dO7HwaxUJmw4"
   },
   "outputs": [],
   "source": [
    "classes= ['squiggle', 'narrowband', 'narrowbanddrd','noise' ]\n",
    "tr_classes= ['squiggle', 'narrowbanddrd','noise' , 'narrowband']\n",
    "def plot_sample(X, Y, index):\n",
    "    plt.figure(figsize = (20,4))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[Y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6tiZF7sl6wm"
   },
   "outputs": [],
   "source": [
    "# for i in range(3000,3010,1):\n",
    "#   plot_sample(x_train, y_Train, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBbptjB4K2qe"
   },
   "outputs": [],
   "source": [
    "# for i in range(1000,1010,1):\n",
    "#   plot_sample(x_train, y_Train, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Lu0T34QCSkVn"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(x_train).reshape(3200,64, 128,1)\n",
    "X_test = np.array(x_test).reshape(800,64,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UFKV47gObwY"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import datasets,layers,models,Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0otsZ64Rdmu"
   },
   "outputs": [],
   "source": [
    "model_cnn1 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'), # Try (5,3)--------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ----------------------------------------------------------------\n",
    "    \n",
    "        layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'), # Try (4,3)------------------------\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ------------------------\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn1.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate = 0.0003, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_1=model_cnn1.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtI-jod_twuY"
   },
   "outputs": [],
   "source": [
    "model_cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLnNj_mAU_f2"
   },
   "outputs": [],
   "source": [
    "H1 = pd.DataFrame(MODEL_1.history)\n",
    "H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STazSvFGU7IO"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7kmOeyGa-D3"
   },
   "outputs": [],
   "source": [
    "loss_plot = H1.plot(y = 'loss', title = 'Loss vs Epochs', legend = False)\n",
    "loss_plot.set(xlabel = 'Epochs', ylabel = 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emqspDRna_C-"
   },
   "outputs": [],
   "source": [
    "acc_plot = H1.plot(y = 'accuracy', title = 'accuracy vs epochs', legend = False)\n",
    "acc_plot.set(xlabel = 'epochs', ylabel = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwXIhPoBXFaU"
   },
   "outputs": [],
   "source": [
    "y_pred = model_cnn1.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "# y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hK7JaznSZoA_"
   },
   "outputs": [],
   "source": [
    "# y_Train.shape\n",
    "y_Test = np.array(y_Test)\n",
    "# y_Test.reshape(-1,1)\n",
    "y_Pred = np.array(y_classes)\n",
    "# y_Pred.shape\n",
    "# y_Pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Whpd9MuZNpd"
   },
   "outputs": [],
   "source": [
    "# y_pred.shape\n",
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U4MwsPEUmky"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_Test, y_Pred))\n",
    "# Classification Report classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Q554VRpro-0"
   },
   "outputs": [],
   "source": [
    "model_cnn2 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(7,2),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(5,2),activation='relu'), # Try (5,3)--------------------\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ----------------------------------------------------------------\n",
    "    \n",
    "        layers.Conv2D(filters=128,kernel_size=(3,2),activation='relu'), # Try (4,3)------------------------\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ------------------------\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn2.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate=0.0002,beta_1=0.9, beta_2=0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_2=model_cnn2.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wWNmdu2t33i"
   },
   "outputs": [],
   "source": [
    "model_cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWhVfpQ5r-Uz"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn2.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFxgO4ewsGdI"
   },
   "outputs": [],
   "source": [
    "y_pred = model_cnn2.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_Train.shape\n",
    "y_Test = np.array(y_Test)\n",
    "# y_Test.reshape(-1,1)\n",
    "y_Pred = np.array(y_classes)\n",
    "y_Pred.shape\n",
    "# y_Pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGfbDBUEsNhk"
   },
   "outputs": [],
   "source": [
    "# Classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))\n",
    "print(confusion_matrix(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTMAc522QoKw"
   },
   "outputs": [],
   "source": [
    "model_cnn3 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(4,2),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(3,1),activation='relu'), # Try (5,3)--------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ----------------------------------------------------------------\n",
    "    \n",
    "        layers.Conv2D(filters=128,kernel_size=(2,1),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ------------------------\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn3.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate=0.0001,beta_1=0.9, beta_2=0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_3=model_cnn3.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXunQr1yRU6g"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mlnTZ8zRZtX"
   },
   "outputs": [],
   "source": [
    "y_pred = model_cnn3.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_Test = np.array(y_Test)\n",
    "y_Pred = np.array(y_classes)\n",
    "# Classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))\n",
    "print(confusion_matrix(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EXsKxCLR9sQ"
   },
   "outputs": [],
   "source": [
    "model_cnn4 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(2,2),activation='relu'), # Try (5,3)--------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ----------------------------------------------------------------\n",
    "    \n",
    "        layers.Conv2D(filters=128,kernel_size=(1,1),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ------------------------\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn4.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_4=model_cnn4.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WwzLsx7SEff"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn4.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-NYKORQSGyF"
   },
   "outputs": [],
   "source": [
    "y_pred = model_cnn4.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_Test = np.array(y_Test)\n",
    "y_Pred = np.array(y_classes)\n",
    "# Classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))\n",
    "print(confusion_matrix(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxyDZ7g_UatF"
   },
   "outputs": [],
   "source": [
    "model_cnn5 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(5,3),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(4,3),activation='relu'), # Try (5,3)--------------------\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ----------------------------------------------------------------\n",
    "    \n",
    "        layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'), # Try (4,3)------------------------\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ------------------------\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn5.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate = 0.0002, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_5=model_cnn5.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tiz6DuDxVm7q"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn5.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsrNjFcBVpWd"
   },
   "outputs": [],
   "source": [
    "y_pred = model_cnn5.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_Test = np.array(y_Test)\n",
    "y_Pred = np.array(y_classes)\n",
    "# Classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))\n",
    "print(confusion_matrix(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqTHFqDFV5KM"
   },
   "outputs": [],
   "source": [
    "model_cnn6 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(2,2),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(2,2),activation='relu'), # Try (5,3)--------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ----------------------------------------------------------------\n",
    "    \n",
    "        layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        # layers.Dropout(0.5), # Try ------------------------\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn6.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate = 0.0002, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_6=model_cnn6.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHm-Tv-TV9E5"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn6.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s47L1pkXV_7j"
   },
   "outputs": [],
   "source": [
    "y_pred = model_cnn6.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_Test = np.array(y_Test)\n",
    "y_Pred = np.array(y_classes)\n",
    "# Classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))\n",
    "print(confusion_matrix(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xb8DRieirvgj"
   },
   "outputs": [],
   "source": [
    "model_cnn7 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'), # Try (5,3)--------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "      \n",
    "        layers.Conv2D(filters=64,kernel_size=(2,2),activation='relu'),   \n",
    "\n",
    "        layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "             \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn7.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate = 0.0002, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_7=model_cnn7.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ainXCI2rteh"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn7.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AmjLLQ8rq3x"
   },
   "outputs": [],
   "source": [
    "y_pred = model_cnn7.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_Test = np.array(y_Test)\n",
    "y_Pred = np.array(y_classes)\n",
    "# Classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))\n",
    "print(confusion_matrix(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_CH0C0-uT76"
   },
   "outputs": [],
   "source": [
    "model_cnn8 = models.Sequential([\n",
    "        layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),\n",
    "        \n",
    "        layers.Conv2D(filters=96,kernel_size=(3,3),activation='relu'), # Try (5,3)--------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "      \n",
    "        layers.Conv2D(filters=96,kernel_size=(3,3),activation='relu'),   \n",
    "\n",
    "        layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "             \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn8.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate = 0.0002, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_8=model_cnn8.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_M9JlfFVuuYO"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(800,64,128,1)\n",
    "model_cnn8.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97uAuGGSutcH"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pred = model_cnn8.predict(X_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_Test = np.array(y_Test)\n",
    "y_Pred = np.array(y_classes)\n",
    "# Classes=['squiggle', 'narrowband', 'narrowbanddrd', 'noise']\n",
    "print(classification_report(y_Test, y_Pred))\n",
    "print(confusion_matrix(y_Test, y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKwlAhBfu8yS"
   },
   "outputs": [],
   "source": [
    "H8 = pd.DataFrame(MODEL_8.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rS0Hhw3dv2u5"
   },
   "outputs": [],
   "source": [
    "loss_plot = H8.plot(y = 'loss', title = 'Loss vs Epochs', legend = False)\n",
    "loss_plot.set(xlabel = 'Epochs', ylabel = 'Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlioeGievz30"
   },
   "outputs": [],
   "source": [
    "acc_plot = H8.plot(y = 'accuracy', title = 'accuracy vs epochs', legend = False)\n",
    "acc_plot.set(xlabel = 'epochs', ylabel = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbXB_ye49fI9"
   },
   "outputs": [],
   "source": [
    "model_cnn9 = models.Sequential([\n",
    "        layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(64,128,1)), # Try (7,3)----------------------\n",
    "        # layers.MaxPooling2D((2,2)), # Try ----------------------------------------------\n",
    "        \n",
    "        layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'), # Try (5,3)--------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "      \n",
    "        layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),   \n",
    "\n",
    "        layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        layers.Conv2D(filters=128,kernel_size=(2,2),activation='relu'), # Try (4,3)------------------------\n",
    "        # layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Dense(256, activation='relu'),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'), # Try ------------------------\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "model_cnn9.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = Adam(learning_rate = 0.0002, beta_1 = 0.9, beta_2 = 0.999),# epsilon=1e-07, amsgrad=False), #Try--------\n",
    "                  metrics = ['accuracy'])\n",
    "MODEL_9=model_cnn9.fit(X_train,y_train, epochs=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyw71Eo5ktWu"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "base_model = keras.applications.MobileNetV2(input_shape=(64,128,1), alpha=1.0, include_top=False, \n",
    "                                            weights='imagenet', classifier_activation='softmax')\n",
    "base_model.trainable = False\n",
    "\n",
    "model1_mnV2 = tensorflow.keras.Sequential([\n",
    "  base_model,\n",
    "  tensorflow.keras.layers.GlobalAveragePooling2D(),\n",
    "  tensorflow.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XByhw434XI-L"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "# from keras.applications import MobileNetV2, VGG16\n",
    "from keras.models import Model\n",
    "pt_model = keras.applications.MobileNetV2(input_shape=input_shape, alpha=1.0, \n",
    "                                                     include_top=False, weights='imagenet', \n",
    "                                                     classifier_activation='softmax')\n",
    "for idx, layer in enumerate(pt_model.layers):\n",
    "  print(idx, layer, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ibvpkfLjFM8"
   },
   "outputs": [],
   "source": [
    "for layer in pt_model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "last_layer = pt_model.get_layer('block_5_expand_BN')\n",
    "last_output = last_layer.output\n",
    "    \n",
    "# Flatten the output layer to 1 dimension\n",
    "x = GlobalMaxPooling2D()(last_output)\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# Add a dropout rate of 0.5\n",
    "x = Dropout(0.5)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "model_mnV2 = Model(pt_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iq3FF7Tj3fl"
   },
   "outputs": [],
   "source": [
    "model_mnV2.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_mnV2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLCJTca_j2iI"
   },
   "outputs": [],
   "source": [
    "training3 = model_mnV2.fit(train_generator,\n",
    "                      steps_per_epoch=nb_train_samples,\n",
    "                      epochs=30,\n",
    "                      validation_data=valid_generator,\n",
    "                      validation_steps=nb_valid_samples,\n",
    "                      callbacks=[earlystop])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SETI_Assign1_Final_15.10.21.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
